 The History of Technological Anxiety and the Future of Economic Growth: Is This Time Different? Journal of Economic Perspectives—Volume 29, Number 3—Summer 2015—Pages 31–50 T echnology is widely considered the main source of economic progress, but it has also generated cultural anxiety throughout history. From generation to generation, literature has often portrayed technology as alien, incomprehensible, increasingly powerful and threatening, and possibly uncontrollable (Ellul 1967; Winner 1977). The myth of Prometheus is nothing if not a cautionary tale of these uncontrollable effects of technology. In Civilization and its Discontents, Sigmund Freud (1930 [1961], pp. 38–39) assessed what technology has done to homo sapiens, making him into a kind of God with artificial limbs, “a prosthetic God.
 When he puts on all his auxiliary organs he is truly magnificent; but those organs have not grown onto him and they still give him much trouble at times.” So it is surely not without precedent that the developed world is now suffering from another bout of such angst. In fact, these worries about technological change have often appeared at times of flagging economic growth. For example, the Great Depression brought the first models of secular stagnation in Alvin Hansen’s 1938 book Full Recovery or Stagnation? Hansen drew on the macro economic ideas of John Maynard Keynes in fearing that economic growth was over, with population growth and technological innovation exhausted. Keynes was also drawn into the debate and offered a meditation on the future of technology and unemployment in his well-known essay, “Economic Possibilities for our Grandchildren.
” The History of Technological Anxiety and the Future of Economic Growth: Is This Time Different? ■ Joel Mokyr is Robert H. Strotz Professor of Arts and Sciences and Professor of Economics and History, Northwestern University, Evanston, Illinois. Chris Vickers is Assistant Professor of Economics, Auburn University, Auburn, Alabama. Nicolas L. Ziebarth is Assistant Professor of Economics, University of Iowa, Iowa City, Iowa.
 Their email addresses are j-mokyr@ northwestern.edu, czvickers@auburn.edu, and nicolas-ziebarth@uiowa.edu. doi=10.1257/jep.
29.3.31 Joel Mokyr, Chris Vickers, and Nicolas L. Ziebarth mailto:j-mokyr@northwestern.edu mailto:j-mokyr@northwestern.edu mailto:nicolas-ziebarth@uiowa.
edu 32 Journal of Economic Perspectives This was originally written as a set of lectures in 1928 after a decade of dismal economic performance in the United Kingdom and then revised in 1930 to incorporate remarks about the Great Depression (Pecchi and Piga 2008, p. 2). Keynes (1930) remained optimistic about the future in the face of staggering unemployment, writing: “We are suffering, not from the rheumatics of old age, but from the growing-pains of over-rapid changes, from the painfulness of readjustment between one economic period and another. The increase of technical efficiency has been taking place faster than we can deal with the problem of labour absorption; the improvement in the standard of life has been a little too quick.” More recently, Winner’s (1977) “Autonomous Technology: Technics-out-of-Control as a Theme in Political Thought” was published during the economic doldrums of the mid and late 1970s. Today, distinguished economists such as Lawrence Summers (2014), in a speech to the National Association of Business Economists, can be heard publicly musing about the possibility of secular stagnation.
 In his Martin Feldstein lecture, Summers (2013b) discussed a downright “neo-Luddite” (that famous protest movement against technological innovation in nineteenth century England) position on the effects of technology for long-term trends in employment. Anxieties over technology can take on several forms, and we focus on what we view as three of the most prominent concerns. The first two worries are based on an “optimistic” view that technology will continue to grow and perhaps accelerate. First, one of the most common concerns is that technological progress will cause widespread substitution of machines for labor, which in turn could lead to technological unemployment and a further increase in inequality in the short run, even if the long-run effects are beneficial. Second, there has been anxiety over the moral implications of technological process for human welfare, broadly defined. In the case of the Industrial Revolution, the worry was about the dehumanizing effects of work, particularly the routinized nature of factory labor.
 In modern times, perhaps the greater fear is a world like that in Kurt Vonnegut’s 1952 novel Player Piano, where the elimination of work itself is the source of dehumanization (for example, Rifkin 1995). As Summers said (as quoted “not perfectly verbatim” in Kaminska 2014), while “[t]he premise of essentially all economics . . . is that leisure is good and work is bad. .
 . . economics is going to have to find a way to recognize the fundamental human satisfactions that come from making a contribution . . .” A third concern cuts in the opposite direction, suggesting that the epoch of major technological progress is behind us.
 In recent years, even in the face of seemingly dizzying changes in information technology, pessimists such as Gordon (2012), Vijg (2011), and Cowen (2010) have argued that our greatest worry should be economic and productivity growth that will be too slow because of, for example, insufficient technological progress in the face of “headwinds” facing western economies. Some of these so-called “headwinds,” including slow productivity and population growth, formed the basis of Hansen’s (1939) secular stagnation hypothesis. The argument of this paper is that these worries are not new to the modern era and that understanding the history provides perspective on whether this time is truly different. The next section of the paper considers the role of these three anxieties among economists, primarily Joel Mokyr, Chris Vickers, and Nicolas L. Ziebarth 33 focusing on the historical period from the late 18th to the early 20th century, while the final section offers some comparisons between the historical and current manifestations of these three concerns. Anxieties over Technology from the Industrial Revolution to the Great Depression Short-Term Disruption, Long-Term Benefits We begin with the first technological transition that was extensively written about and debated in real-time by economists and many others, the Industrial Revolution.
 From the late 18th century onward, the debate centered on how technological progress affected workers and how these effects might differ between the short run and the long run. In the short run, could technological innovation lead to lower employment or lower wages? If there were long-run negative effects, were these innovations still worthwhile? Prominent economists of that time had divided opinions. For example, Thomas Mortimer (1772, p. 104) wrote that he wished never to see machines such as saw mills and stamps as they would “exclude the labour of thousands of the human race, who are usefully employed .
 . .” In a much-debated chapter inserted into the third edition of his Principles of Political Economy, David Ricardo presented a candid admission of a change of opinion. In the past, Ricardo (1821 [1971], p. 380) noted, he had been convinced that an application of machinery to any branch of production was a general good, but he had more recently concluded that the “substitution of machinery for human labour is often very injurious to the interests of the class of labourers . .
 . [It] may render the population redundant and deteriorate the condition of the labourer.” Berg (1980, pp. 67–68) underlines the eccentric economics of Ricardo on the long- versus short-run effects of technological change. Ricardo did not think that technological unemployment was the necessary result of technological progress in a specific industry. However, because of his “wage-fund” theory in which capital spent on machinery was taken out of the funds available to pay for workers, employment might be reduced as a result of investment in machinery.
 Ricardo felt that this case was a rather restrictive one, and that in the long run higher productivity would lead higher saving and eventually rising demand for labor. While many writers conceded possibly negative effects of machinery on employment in the short run, they typically distinguished short-run dislocations from possible long-run effects. For example, Sir James Steuart (1767, vol. I, p. 122), widely regarded as one of the most insightful writers on economics before Adam Smith, wrote that he would disapprove of machinery only in cases in which it “might force a man to be idle” who would have no other way of earning his bread than his current employment. But normally, Steuart argued, technological unemployment would occur only if the innovation was introduced very suddenly.
 Even then, the dislocation to employment would be temporary, while the advantages of higher productivity would be permanent. Post-Ricardians such as John Stuart Mill conceded that improvements could 34 Journal of Economic Perspectives temporarily be injurious to workers, but Mill (1848 [1929], p. 97) quickly added: “I do not believe that . . . improvements in production are often, if ever, injurious, even temporarily, to the labouring classes in the aggregate.
” Karl Marx, from a rather different perspective, also argued that technological unemployment was a serious problem in the short run, in the broader context of the immiseration of workers under a capitalist system. But for Marx as well, technological improvement was part of a social and political process that would lead eventually to widespread prosperity. (Of course, the Marxist vision of progress also eventually required a wholesale overthrow of the existing capitalist economic system.) Some of the most interesting thinking on the long-run effects of technology came from, for a lack of a better term, “reactionaries.” These writers, while conceding the power of technology, were deeply doubtful on whether it benefited society as a whole. Yet many resigned themselves to the change and even encouraged adoption for noneconomic reasons.
 For example, William Mildmay (1765, p. 42) conceded that machinery might “destroy the necessity of labour” but still recommended its introduction, because other nations would otherwise outcompete Britain. This fatalism about technology was perhaps best reflected in writing of intellectuals in the antebellum US South, as in some examples cited by Genovese (1992, p. 21): “The fate of Russia in the Crimean War, declared Thomas L. Clingman, the powerful politician from North Carolina, teaches the need for railroads as a matter of military survival. Even the most ‘reactionary’ of southerners—even George Fitzhugh—had to agree.
” Other Southerners such as Thomas Roderick Dew of Virginia saw the tension between slavery and the fact that “[m]ilitary might depended upon that vaunted economic progress which the free-labor system excelled in generating” (Genovese 1992, p. 19). For these writers, technology adoption had an aspect of the prisoner’s dilemma, in which each party would be foolish to pass on utilizing the newest advances even if the end result was to make everyone worse off. Given all of this handwringing over short-run costs of technology, one may have thought that technological unemployment during the Industrial Revolution was a serious problem. However, it is one thing to argue that in certain configurations some temporary unemployment can be caused by the introduction of “machinery.” It is another to demonstrate that such technological unemployment actually occurred on a large scale, and indeed the evidence is that it did not (Mokyr 2002, p.
 256). In fact, on closer examination of the better-known British protests of the day that were supposedly focused technological innovations in textiles, like the Luddite (1811–16) and Captain Swing (1830–32) riots, the role actually played by the concerns of laborers about being replaced by machinery has been greatly exaggerated. These upheavals were comparable to the “Occupy Wall Street” movement (though substantially more frightening to those nearby) with a multitude of causes and a somewhat unclear set of goals. The Luddite riots started in Nottingham where workers were more concerned with low wages and work practices, in general, rather than mechanization per se. In Lancashire, machine-breaking seems to have been the result of machines being a convenient target in a dispute between The History of Technological Anxiety and the Future of Economic Growth 35 industrialists and their employees. In Yorkshire, on the other hand, wool-croppers were well-organized and clearly determined to slow down mechanization (Thomis 1970).
 Similarly, the Swing riots were as much aimed against cheap Irish migrant labor as they were directed against the new steam-threshers (Stevenson 1979, p. 243), yet they were one of the few instances in which mechanization was actually slowed down by political action. Indeed, the broad claim that Britain’s working-class leaders in the early decades of the 19th century resisted the machine because of the technological unemployment it caused is difficult to square with complaints about “long hours of alienated factory labour, and the smoking blight of rapidly expanding industrial towns” (Berg 1980, p. 17). The problem with the factories was not in the low quantity of work they offered, but the low quality of work in the mills. Still, there is no doubt that by disrupting the demand for certain types of labor, the Industrial Revolution caused considerable distress, even if on balance it may not have reduced the overall demand for labor.
 In the British economy in the early 19th century, the workers most affected by an influx of capital investment were those employed in domestic cottage industries, which traditionally had very low capital intensity and low productivity. The handloom weavers and frame knitters with their little workshops were quite rapidly wiped out by factories after 1815 (Bythell 1969). While factory wages were rising, the real incomes of most domestic workers and independent artisans were falling (Allen 1992, pp. 255–56; 296–97; Lyons 1989). Modern work by Goldin and Katz (1998) has documented the skill-biased changes in technology from the early 20th century United States, while that of Katz and Margo (2013) has found a “hollowing out” in the skill distribution of 19th-century American manufacturing. In the early 19th century, the gaps in wages constituted the market “signal” that the death knell was sounding for a rural-industry lifestyle and culture based on cottage industries.
 This process was surely a painful one. Vickers and Ziebarth (2012) have suggested that some of this pain may have spilled over into higher rates of criminal behavior for those with skills depreciated by mechanization. Still, this transition was by and large a one-generation affair (Lyons 1989). Furthermore, after 1840, emigration to North America became increasingly an option for those whose livelihood disappeared. The 19th-century workers who had jobs in the newly industrializing part of the economy had legitimate concerns with regard to wages, standards of living, and inequality. Precisely when the innovations of the Industrial Revolution translated into higher median living standards in England is a matter of dispute.
 Feinstein (1998) argues for almost no increase in wages prior to 1815, and even by the mid-1850s he estimates an increase of less than 30 percent compared to the 1780s. The record in the United States at that time is similarly controversial and uneven; Margo (2000, p. 51) finds generally positive rates of real wage growth from 1820–60, but with considerable variation across regions, time, and occupational class. For artisans in the Midwest, for example, wages actually fell slightly over this period. In the Northeast, real wages rose slowly in the 1820s and 1830s, with a relatively rapid rise in the 1840s. 36 Journal of Economic Perspectives Wages, of course, are an incomplete measure of the standard of living, and the nonpecuniary effects of industrialization on well-being have been much debated.
 Using commodity data, Mokyr (1988) finds a rate of consumption growth between 1815–1819 and 1845–1849 of well under a half a percent a year, with even that mostly concentrated in the later years. On the other hand, scholars such as Williamson (1981) characterize the urban disamenities associated with industrialization as “trivial”: for example, coal smoke may have been unhealthy, but cheap fuel also offered warm houses and better-cooked food. However, the evidence for the pessimistic case has grown stronger. In a review, Voth (2004) argues that the modest real wages gained by 1850 were “bought by longer hours of more intensive work, performed in more dangerous and unhealthy workplaces.” Estimates of inequality are still somewhat conjectural for this period and particularly sensitive to measurement issues and the construction of price indices for different classes. Still, Lindert (2000) suggests that inequality in Britain rose most quickly between 1740 and 1810, and at a somewhat slower rate after that.
 Allen (2005) argues for a sharpening of income inequality in Britain between 1780 and 1850. In the United States, the timing of rises in inequality is more disputed. Nevertheless, with regard to wages, standard of living, and inequality, the position of workers was at best uneven, even if technological unemployment per se was largely an exaggerated issue. In the end, the fears of the Luddites that machinery would impoverish workers were not realized, and the main reason is well understood. The mechanization of the early 19th century could only replace a limited number of human activities. At the same time, technological change increased the demand for other types of labor that were complementary to the capital goods embodied in the new technologies.
 This increased demand for labor included such obvious jobs as mechanics to fix the new machines, but it extended to jobs for supervisors to oversee the new factory system and accountants to manage enterprises operating on an unprecedented scale. More importantly, technological progress also took the form of product innovation, and thus created entirely new sectors for the economy, a development that was essentially missed in the discussions of economists of this time. The children of the displaced handloom weavers not only had the option to work in machine-intensive cotton mills; they could also become trained engineers and telegraph operators. Nineteenth-century political economists lacked an ability to predict new job categories like the personal fashion consultants, cyber security experts, and online-reputation managers of the twenty-first century. One sign that the magnitude of technological unemployment and labor displacement turned out to be relatively small during this time period—and that questions of the treatment and standard of living of workers using the new technologies loomed larger—was that the “machinery question” largely disappeared from the discourse of classical, non-Marxist political economy (Berg 1980, p. 130) in the late 19th century.
 While popular attention from time to time returned to the question of technological unemployment, the economics profession was dismissive. Upward trends in living standards could not be denied, and so as Woirol (1996, p. 20) notes, “the employment effects of technological change ceased to be seen as a relevant Joel Mokyr, Chris Vickers, and Nicolas L. Ziebarth 37 problem.” Among his examples, Woirol mentions Wells (1889, p. 374), who notes “undoubtedly a feeling of apprehension among the masses that the opportunities for employment .
 . . are less favorable than formerly,” but concludes there is “little evidence thus far that labor has been disturbed or depressed” by machinery. Similarly, Woirol mentions the economist (and later president of Yale) Arthur Hadley (1896), who responded to the claim that mechanization “displaces a large amount of human labor, thus taking income away from employees” by noting there had been “a conspicuous increase of employment in those lines where improvements in machinery have been greatest.” The question did return in the early 20th century in the writings of Knut Wicksell (1901 [1934]) who argued, in a pure neoclassical model, that technological progress could either lower or raise the marginal product of labor, and thus wages, depending on whether the technology was labor-saving or labor-augmenting. Wicksell (p.
 164) concluded, “The capitalist saver is thus, fundamentally, the friend of labour, though the technical inventor is not infrequently its enemy.” However, Wicksell was careful to distinguish possible short-run deleterious effects from long-run outcomes and so continued, “The great inventions by which industry has from time to time been revolutionized at first reduced a number of workers to beggary. . . . [but then] as accumulation continues, these evils must disappear .
 . . and wages will rise” (p. 164). At about the same time, J. B.
 Clark (1907, p. 452) noted, in a widely cited remark: “The well-being of workers requires that progress should go on, and it cannot do so without causing temporary displacement of laborers.” These comments from Wicksell and Clark roughly summarize the consensus of the economics profession in the early twentieth century. During the Great Depression, a seemingly never-ending period of high unemployment, the attraction of the technological unemployment hypothesis could not be fully resisted. Ewan Clague (1935), a labor economist who was to serve as Commissioner of Labor Statistics for the Department of Labor from 1946 to 1965, stated in the pages of the Journal of the American Statistical Association that “the present outlook is for the rate of displacement of labor to exceed the rate of reabsorption so that technological employment will continue to be large.” He concluded by noting that “in time .
 . . the surplus of older workers will be eliminated by age and death.” Part of this worry was based not on rapid innovations in manufacturing, but on labor-saving changes in agriculture such as the tractor, which were one factor driving massive flows of people from rural areas to the cities. Others such as Edna Lonigan (a US Department of Labor economist), while cognizant of the debates over the effects of labor saving technology, rejected this argument. Lonigan (1939, p.
 255) stated flatly that “our present unemployment has little to do with machines” and argued that there is no necessary connection between innovation and unemployment. Instead “it is in the failure of the price system . . . to permit the creation of new employment, that the source of the worker’s growing insecurity is to be found.” Of course, grasping for a secular supply-side explanation of high unemployment is not unique to the Depression of the 1930s.
 Many people have been quick to jump to such an explanation in the 38 Journal of Economic Perspectives Great Recession of 2007–2009 and its aftermath, even when a deficiency in aggregate demand may offer a more plausible explanation. In the end, one should be careful in dismissing the performance of earlier generations of economists in predicting the effects of technological development on employment. While the predictions of widespread technological unemployment were, by and large, wrong, we should not trivialize the costs borne by the many who were actually displaced. It is true that, in the long run, wages for laborers increased to reflect dramatically increased productivity. It is also true that, for the Industrial Revolution, by many estimates it took longer than an average working lifetime to do so, and in the long run, we are all dead. Technology and the Alienation of Labor Besides questions of employment and wages, technological innovation brings worries about the nature of work and the so-called alienation of labor.
 Even before the Industrial Revolution, and in between extolling the value of specialization, Adam Smith (1776, p. 385) cautioned against the moral effects of this process, as when he wrote: “The man whose whole life is spent in performing a few simple operations . . . generally becomes as stupid and ignorant as it is possible for a human creature to become.” Karl Marx, more well-known than Smith as a critic of industrialization, argued that the capitalist system alienates individuals from others and themselves.
 In the Economic and Philosophic Manuscripts of 1844, Marx wrote, “The height of this servitude is that it is only as a worker that he can maintain himself as a physical subject, and that it is only as a physical subject that he is a worker” (as cited in Elster 1986, p. 38). This view of industrial capitalism as treating people like cogs in the machine became a central preoccupation of Marx and his followers, but it was no means unique to leftist revolutionaries. One can see it reflected in Thomas Jefferson’s (1787, chap. 19) rosy views about the “yeoman farmer” as the basis for democracy: “Those who labour in the earth are the chosen people of God, if ever he had a chosen people, whose breasts he has made his peculiar deposit for substantial and genuine virtue.” Even many reactionary supporters of slavery in the United States, such as John C.
 Calhoun (1837) came to a similar conclusion, viewing what some called the Northern wage-slavery system as one way in which one portion of the community lived on the labor of the other, outright slavery being the other. For Calhoun, all economic systems entailed coercion and limited freedom. Chattel slavery at least had the feature that a certain class of individuals—the slave-owners—could live a life elevated above the dirty, nasty nature of work. The factories created by industrialization offered no such option. Some such as Thomas Roderick Dew (quoted in Genovese 1992, pg. 18) held up slavery as a model because “only slavery .
 . . could guarantee republican liberties for the propertied, security for the propertyless, and stability for the state and society.” It is not as if the horrors of factory work were invented out of whole cloth. In the early days of the factory system, work conditions were often difficult, harsh, and unforgiving. The British Parliament in 1837 published a report titled “Evils of The History of Technological Anxiety and the Future of Economic Growth 39 the Factory System: Demonstrated by Parliamentary Evidence,” partially focused on child labor.
 It contained graphic descriptions of accidents involving “the integuments, and the muscles, and the skin stripped off down to the bone, and in some instances a finger or two might be lost” (Wing 1837 [1967], p. clxxii). Such examples could be multiplied ad nauseam. Near the end of the 19th century, the Factory Inspectors in the State of Illinois (1895, p. 79) described factory work as involving “a degree of toil disproportionate to the condition and capacity of those engaged, while the effects of the unremitting and monotonous character of most of the work, can but stand in direct causative relation to the disturbances and depressions . .
 . the unremitting and monotonous character of factory work [is] productive of lessened vigor and vitality.” For Marx and others, it was not just that new factory jobs were dirty and dangerous. Jeffersonian encomiums aside, the pastoral life of small shop owners or yeoman farmers had not entailed particularly clean and safe work either. Instead the point was that this new work was in a deeper way unfit for humans and the process of covert coercion that forced people into these jobs and disciplined them while on the job was debasing. Thompson (1963, p.
 305) argues that the factories were resisted even before the use of power because of “the discipline; the factory bell or hooter; the time-keeping which over-rode ill-health, domestic arrangements, or the choice of more varied occupations.” One need not accept the reactionary view that such constraints on paid workers made 19th-century wage labor not very different from slavery to recognize, as many social reformers of the time did, that a lack of personal control over work raises meaningful issues. There is little disagreement that work in the preindustrial period was much more variable for both predictable reasons (the seasonal pattern of agriculture) and unpredictable ones (driven by the small-scale nature of home production). Still these small-scale enterprises gave at least the worker-owners the appearance of autonomy in when and how they worked. The rise of the factory system ended that freedom, bringing jobs linked to a system of a set hours that most workers labor under still today. We should be careful not to take too seriously the idealization of preindustrial work by historians such as Thompson (1963), who wrote on the “work-life balance” present in preindustrial revolution economies.
 Freudenberger and Cummins (1976) argue that rather than reflecting some desire to consume leisure, what appeared to be a relatively short average pre–Industrial Revolution work week may have been primarily for necessary recuperation for work in the presence of high rates of disease and undernourishment. Part of the loss of control in moving to factory work involved the physical separation of home from place of work. While today people worry about the exact opposite phenomenon with the lines between spheres of home and work blurring, this disjunction was originally a cause of great anxiety, along with the separation of place-of-work from place-of-leisure. Preindustrial societies had “no clearly defined periods of leisure as such, but economic activities, like hunting or market-going, obviously have their recreational aspects, as do singing or telling stories at work” (Thomas 1964, p. 52). Workers who were “considerably dissatisfied, because they 40 Journal of Economic Perspectives could not go in and out as they pleased” (Pollard 1963) had to be habituated into the factory system, by means of fines, locked gates, and other penalties.
 The preindustrial domestic system, by contrast, allowed a much greater degree of flexibility. The process of industrialization also reduced the large share of transactions before the Industrial Revolution that took place within a context of personal relationships. Premodern commercial institutions were based on personal relationships that allowed for trading in the absence of well-developed formal and legal institutions (as discussed in Greif 1993). Factory work was part of a process in which personal relationships became less important in labor markets. Some such as Zucker (1986) have suggested that the “social overhead capital sector,” consisting of intermediaries such as banking and insurance, increased dramatically in the late 19th century in response to the breakdown in traditional reputation mechanisms that were driven by personal contact. Finally, there are claims that as work life and personal life separated, what was perceived as usual or virtuous behavior may have shifted, too.
 As industrialization in the 19th century eroded the transparent link between effort and success as understood by artisans, the moral understanding of work was transformed with the disappearance of what has been called the “moral economy,” making room for a market economy. The changing nature of work provided purchase to those who viewed the rising standard of living associated with industrialization as something of a poisoned chalice. Again a number of antebellum southerners such as Henry William Ravenel held this view. As Ravenal wrote (cited in Genovese 1992, p. 30), “It is too sad proof that with all the progress made in the Arts and Sciences . .
 . with all the great improvements in manufactures and material prosperity, mankind are no better now than at any previous time—the evil passions of our fallen state are just as prominent and as easily brought into exercise . . .” Historical Perspectives on a Horizon for Technological Progress The question of whether sustained progress faced an inevitable horizon, technological or otherwise, has roots stretching back to classical antiquity. Robert Nisbet (1980) argued in his book History of the Idea of Progress that the ancients already ascribed to the “Idea of Progress,” the claim that improvement in the moral and economic lot of man was possible.
 As one example, while the story of Prometheus suggests a mixed view of progress, Nisbet notes that Prometheus defends himself by pointing out the terrible condition in which he found mankind and what people were able to achieve with the gift of fire. This optimism continues through the Romans, particularly in the Lucretius’ De Rerum Natura (On the Nature of Things), where he sketches out perhaps the earliest evolutionary account of the universe starting from atoms in the void. But while the idea that progress is possible and preferable was not new in the classical economists of the 18th and 19th centuries—or more broadly, to the Enlightenment period—the Enlightenment was a period in which the belief in progress became a central organizing concept of the discourse on the dynamics of society. Progress included material progress, or what we would think of today as economic growth. The conscious belief in the possibility of continuous betterment Joel Mokyr, Chris Vickers, and Nicolas L. Ziebarth 41 of society and a detailed set of prescriptions for how to bring it about were innovations associated with the Enlightenment (Mokyr 2010, p.
 33). Perhaps most striking is the “faith,” for lack of a better word, that these Enlightenment thinkers had in progress. They believed that progress was possible, that it was desirable, and that they knew how to bring it about. Others weren’t so sure. Of course, the age of industrialization had its skeptics and pessimists. But our focus here is on those who were “pessimistic” about technology because they did not think much was left to be done.
 Consider the comment from Nobel prize-winning Albert Michelson (1903, pp. 23–25): “The more important fundamental laws and facts of physical science have all been discovered, and these are so firmly established that the possibility of their ever being supplanted in consequence of new discoveries is exceedingly remote.” He goes on to quote a quip sometimes attributed to Lord Kelvin that “our future discoveries must be looked for in the sixth place of decimals.” With regards to economic progress, a number of 19th century economists came close to Lord Kelvin’s view. John Stuart Mill wrote about the “stationary state” in his Principles of Political Economy (1848, book IV, chap. VI): “It is only in the backward countries of the world that increased production is still an important object: in those most advanced, what is economically needed is a better distribution .
 . .” For Mill, this stationary state of development did not imply no improvement whatsoever. “[A] stationary condition of capital and population implies no stationary state of human improvement. . .
 . Even the industrial arts might be as earnestly and as successfully cultivated, with this sole difference, that instead of serving no purpose but the increase of wealth, industrial improvements would produce their legitimate effect, that of abridging labor.” This perspective is quite similar to the standard view of mid-19th century socialists descending from Marx’s thinking about a communist society where alienation of workers from labor would end. John Maynard Keynes (1930) set out a related view of technological progress in his essay, “Economic Possibilities for our Grandchildren.” Keynes glimpsed a far-off technological horizon, where “for the first time since his creation man will be faced with his real, his permanent problem—how to use his freedom from pressing economic cares, how to occupy the leisure, which science and compound interest will have won for him, to live wisely and agreeably and well.” For Keynes, the old Adamite adage that mankind would earn a living “in the sweat of thy brow” (as written in Genesis, 3:19) would change gradually over time: “For many ages to come the old Adam will be so strong in us that everybody will need to do some work if he is to be contented.
 We shall do more things for ourselves than is usual with the rich to-day, only too glad to have small duties and tasks and routines. Three-hour shifts or a fifteen-hour week may put off the problem for a great while. For three hours a day is quite enough to satisfy the old Adam in most of us!” Keynes was truly hopeful for such an outcome, but in a functional sense, this view of the future seems not much different from dystopias such as in the 2008 movie Wall-E, where humans free from economic cares spend their time floating on a futuristic version of a “lazy river.” 42 Journal of Economic Perspectives At least in the time of Keynes (as compared to the earlier generations of economists), this future of radically reduced work hours would have followed naturally from simple extrapolation of ongoing trends. Whaples (2001) noted that the work week in US manufacturing declined from 59.
6 hours in 1900 to 50.6 in 1930. At that rate of decline, the work week would have fallen to 25.4 hours by 2015. To the extent there was a decline in the number of people employed, and abstracting from the business cycle, the change in work in the late 19th and early 20th century concentrated in the young and old. From 1880 to 1920, the male labor force participation rate fell from 87.
3 to 78.8 percent among those aged 65–69, but actually increased a tiny bit from 97.5 to 98.0 percent among those aged 40–44 (Sobek 2001). The extrapolations of the end of work and “stationary states” were built on a model in which eventually people would have their fill, and no more economic progress would be necessary. It was taken as given that the level of technological progress necessary to reach this stage was possible.
 Whether there was additional technology to discover afterwards was beside the point. Some technological pessimists today come close to the “stationary state” theorists by drawing on a favorite analogy that the low-hanging fruit of technology progress have been picked; others view the limits on technological progress as epistemological—there are limits on what we can know. Looking Ahead Technology and the End of Work? While we should not fault the lack of imagination of 19th century political economists in predicting the jobs of tomorrow, the limits they placed on the ways in which human labor could be used do seem peculiar from a modern viewpoint. The mechanical innovations of the Industrial Revolution acted as a substitute for human (and animal) strength as well as dexterity, but the machines of that time could not reason, compare, compute, read, smell, sense, hear, or make snap decisions. However, if artificial intelligence and robotics continue on their present trend, future machines will be able to carry out these human capabilities, at least in certain contexts and to a certain extent.
 Thus, it seems frighteningly plausible that this time will be different, and large sections of the labor market will be dislocated or “hollowed out,” in the Katz and Margo (2013) terminology. Some scholars such as Beaudry, Green, and Sand (2013) have suggested that a peak in demand for high-skilled workers and cognitive tasks already occurred around the year 2000. In some theoretical models, as in Sachs, Benzell, and LaGarda (2015), a rise in “robotic productivity,” which substitutes completely for labor, can result in declines in consumption, at least in the short term. But it is worth recalling that such predictions have been made repeatedly in the recent past. For example, 20 years ago in the mid-1990s, Rifkin (1995) described the spread of technology as “[l]ike a deadly epidemic inexorably working its way through the marketplace, the strange, seemingly inexplicable new economic disease spreads, destroying lives and destabilizing The History of Technological Anxiety and the Future of Economic Growth 43 whole communities in its wake” (p. 3) and cited approvingly a union leader who predicted “that within thirty years, as little as 2 percent of the world’s current labor force ‘will be needed to produce all the goods necessary for total demand’” (p.
 8). As we peer into the hazy future, we find it useful to distinguish two possible effects of the substitution of capital for labor: 1) how much people will work on average; and 2) how that work will be distributed. Leisure has increased over the medium term and the long term. Maddison’s (2001, p. 347) computations show that between 1870 and 1998 the number of annual hours worked per employee in the highly industrialized western economies fell almost precisely by half, from roughly 2,950 hours per worker in 1870 to 1,500 hours per worker in 1998. Since 2000, OECD figures show another decline: the OECD average fell by 75 hours worked per year (although less in the United States).
 For economists, it would seem peculiar to fret too much about a long-term decline in work hours: indeed, the earlier discussion pointed out that there is a tradition of economists either forecasting or hoping that technology would reduce the need for work hours. On the other hand, some economists and other social theorists have suggested that a reduced workweek is not an unalloyed good, because of underlying preferences for accomplishment and labor for its own sake. Freeman (2008, p. 141), for example, suggests that “evolution presumably imbued us with a work ethic for our survival and not a Garden of Eden existence.” Phelps (2008, p. 101) writes that “if a challenging career is not the main hope for self-realization, what else could be?
” Also recall Summers’s call (as quoted in Kaminska 2014) for economists to “recognize the fundamental human satisfactions that comes from making a contribution.” It seems plausible that attitudes toward work and the work ethic itself are not a hard-wired human universal, but rather a culturally conditioned set of beliefs and may not persist in the same form in the face of changes in the structure of the economy induced by technological change. After all, through much of history there has been a leisure class of (mostly) landowners who rarely felt the need to get dirt under their fingernails. Keynes (1930) viewed the old Adamite adage of “in the sweat of thy brow” as quite dispensable. And as mentioned above, Keynes (1930) noted that with the decline of work, man must face the problem of how to occupy his leisure. Here technological progress has clearly changed the rules of the game.
 One of the underappreciated aspects of twentieth-century technological progress has been the increased marginal utility of leisure through increases in the variety of leisure and declines in the cost of leisure-directed techniques. Of course, the ultimate value of leisure activities is a matter of judgment. As Jeremy Bentham (1825, p. 206) famously wrote: “pushpin [a childish game often associated with a useless waste of time] is of equal value with the arts and sciences of music and poetry.” However, it is no stretch to submit that it may be a net gain to human welfare to have fewer hours spent on a job, driving along US interstate highways, or selling tokens in a London Underground station and more hours using modern technology: for example, to watch dramas or sports of a mind-boggling variety on a high-definition flat screen; to attend virtual rock concerts or operas with high-quality sound; 44 Journal of Economic Perspectives to defeat the Trojans or win the tank battle of Kursk from a living room sofa using a joystick; or to “network” with friends through social media. This modern difference between leisure and work is particularly striking when compared to “leisure” in the preindustrial past that involved a fair amount of sitting in the dark.
 As noted, there has historically been a leisure class of people whose lives seemed quite pleasant, although their leisure activities were labor- or resourceintensive activities like golf, hunting, and formal dances. The United States was historically unusual in lacking this class, and European “visitors to the Northern States commented on the drawn faces and frantic busyness of Jacksonian Americans” and the absence of a leisure class (Rodgers 1978, p. 5). What makes today different is the fact that so much high-quality leisure activity can be accessed by all at low average cost and near-zero marginal cost. If this predicted decline in labor hours worked was spread evenly across the working population, that decline would be a minor concern—particularly with the rise of “quality” leisure. Instead, much like the distribution of income and wealth, work hours appear to be diverging across segments of the population.
 Using US data, Aguiar and Hurst (2007) show that people with less than a high school education increased their leisure by almost ten hours per week from 1965 to 2003 (dominated by an increase in television watching) while college graduates increased by less than one hour per week (with an increase in television watching offset by a large decline in socializing). In a similar vein, Aguiar, Hurst, and Karabarbounis (2013) find that about half of the work hours lost by US workers in the recent recession were reallocated to leisure activity, with most of this accounted for by sleeping and television watching. As an article in The Economist (2014) noted, “the workers who are now working the longest hours . . . also happen to be among the most educated and best paid.
 The so-called leisure class has never been more harried.” The welfare implications of this dual phenomenon in economic inequality of labor and leisure hours need to be further explored. At least part of this widening inequality in hours worked is driven by the highest-skilled workers increasing their work effort, but it is also driven by outright declines in work for lower-skill workers. This change is reflected in relatively high unemployment rates for those with just a high school degree—in March 2015, for example, the US unemployment rate was 6.0 percent for those whose education ended with a high school degree versus 3.5 percent for those with a bachelor’s degree—as well as in the 17-percentage-point difference in labor participation rates between these groups, based on US Bureau of Labor Statistics data.
 A common pattern in recent years is that routine tasks with little unpredictable variability are more likely to be mechanized, while jobs that require continuous adjustment to new information and new physical settings along with fine sensory motor-coordination are more difficult to automate. Many middle-skill jobs, both in manufacturing plants and in offices, have tended to be more susceptible to automation (as Autor discusses in this symposium). However, those middle-skill workers can then end up competing for lower-skill jobs. In this way, we are already seeing some of this labor-saving technology affecting the supply side of the lower-skilled labor force Joel Mokyr, Chris Vickers, and Nicolas L. Ziebarth 45 ( Jaimovich and Siu 2014; Charles, Hurst, and Notowidigdo 2014). Perhaps if these kinds of technological developments lead to an economy where an ever-larger share of the population works for relatively low wages but can still enjoy a high standard of living through a variety of low-cost leisure opportunities, political disruption may be minimal.
 But we do not discount the possibility that these shifts will lead to an era that redefines what goods government is responsible for providing, on a par with the political turmoil that led to the Depression-era New Deal or the creation of the German welfare state in the 19th century. In the end, it is important to acknowledge the limits of our imaginations. Technophobic predictions about the future of the labor market sometimes suggest that computers and robots will have an absolute and comparative advantage over humans in all activities, which is nonsensical. The future will surely bring new products that are currently barely imagined, but will be viewed as necessities by the citizens of 2050 or 2080. These product innovations will combine with new occupations and services that are currently not even imagined. Discussions of how technology may affect labor demand are often focused on existing jobs, which can offer insights about which occupations may suffer the greatest dislocation, but offer much less insight about the emergence of as-yet-nonexistent occupations of the future.
 If someone as brilliant as David Ricardo could be so terribly wrong in how machinery would reduce the overall demand for labor, modern economists should be cautious in making pronouncements about the end of work. Technology and the Characteristics of Work Even if ongoing technological developments do not spell the end of work, they will surely push certain characteristics of future jobs back toward pre-factory patterns. These changes involve greater flexibility in when and where work takes place. Part and parcel of this increase in flexibility is the breakdown of the separation between work and home life. The main way in which flexibility seems to be manifesting itself is not through additional self-employment, but instead through the rise of contract firms who serve as matchmakers, in a phenomenon often driven by technology. For example, Autor (2001) notes that there was a decline in independent contractors, independent consultants, and freelancers as a portion of the labor force from 1995 to 1999—peak years for expansion of information technology industries—though there was a large increase in the fraction of workers employed by contract firms.
 The Census Bureau’s counts “nonemployer businesses,” which includes, for example, people with full-time employment reported in the Current Population Survey but who also received outside consulting income. The number of nonemployer businesses has grown from 17.6 million in 2002 to 22.7 million in 2012. In what is sometimes called the “sharing economy,” firms like Uber and AirBnB have altered industries like cab driving and hotel management by inserting the possibility of flexible employment that is coordinated and managed through centralized online mechanisms. Firms such as oDesk or Amazon’s Mechanical Turk allow for the outsourcing of tasks over the Internet that can be divided into finely sliced components.
 46 Journal of Economic Perspectives It is not surprising that greater flexibility can be a mixed blessing. On one side, it can help in balancing work and family. For example, Goldin (2014) argues that industries in which jobs have more temporal flexibility have greater gender equality in earnings. In a survey of employers, Matos and Galinsky (2014) find that certain kinds of flexibility have become more prevalent since 2008, particularly flexibility with regard to time and place during the day, making it possible for workers to attend to personal or family needs. On the other side, flexibility can be a backdoor for employers to extract more effort from employees with an expectation that they always be accessible. In their report on workplace flexibility, the Council of Economic Advisors (2010) suggest that there has been little change since 1998 in the prevalence of these kinds of job-sharing characterized by a reduction in hours.
 Moreover, a penalty is strongly present for part-time work, across a variety of countries (Bardasi and Gornick 2008). Also, flexibility can often mean variable pay. The use of temp and contract workers in the “on-demand” economy (also known as contingent labor or “precarious workers”) has also meant that these workers may experience a great deal of uncertainty as to how many hours they will work and when they will be called by the employers. Almost 50 percent of part-time workers receive only one week of advance notice on their schedule (as reported in Greenhouse 2014). As a recent cover story in the Economist (2015) has noted, workers in the on-demand economy can end up both flexible and rootless, and this creates a host of new incentive problems and monitoring costs. The rise in flexible scheduling and other technology-driven changes, including telecommuting, have weakened the separation of work and home life.
 The proportion of workers working primarily from home nearly doubled from 1980 to 2010, rising from 2.3 to 4.3 percent (according to data from GlobalWorkplaceAnalytics.com). At the same time, the wage penalty for doing so has nearly disappeared (Bloom, Liang, Roberts, and Ying 2013). This change may have made time at work more pleasant, while occasionally also making time at home less pleasant.
 A number of white-collar professionals can sympathize with the feeling of being “always on,” including doctors on call, lawyers on a case, and academics during the term. But those most affected are lower-income people like Fatimah Muhammad, quoted in Greenhouse (2014) as having “to call the [ Joe Fresh clothing] store each morning, to see whether it needed her to work that day. ‘I felt kind of stuck. I couldn’t make plans,’ said Ms. Muhammad.” The Technological Horizon Making specific predictions about the future of technology or the economy is almost always imprudent.
 That said, we are skeptical for a number reasons that a horizon is relatively near—say, within a few decades—either for technological progress or for the widespread satiation of consumer demand. First, we do not foresee humanity running out of pressing technological problems anytime soon. In many cases, these problems are an outgrowth of previous technological advances. For example, the need for clean energy generation is due to industrialization and its resulting greenhouse gases in the first place. Another striking example is the The History of Technological Anxiety and the Future of Economic Growth 47 need for new antibiotics to the treat the bacteria that have become resistant to the first-generation of such wonder-drugs as penicillin and sulfa. We also expect that competition between firms, nations, and major trading blocs will stimulate continued efforts at technological gains.
 Even 18th-century British writers (such as Mildmay quoted earlier) who were suspicious about the effects of technological change for workers felt compelled to accept the innovations if only to ensure that Britain did not fall behind. Finally, there is an underappreciated growth in the tools available for science and technology researchers. Across the sciences, extraordinary large amounts of data can now be stored and searched. New findings can rapidly be transmitted across the global networks of science and research. As Ridley (2010) pointed out, “The cross-fertilization of ideas between, say, Asia and Europe that once took years, decades, or centuries can now happen in minutes while Australia, the Americas, and Africa eavesdrop.” One field that has been particularly affected by the development of new tools is genetics, particularly the polymerase chain reaction, which has seen the cost of sequencing a single human genome decline from $3 billion spent by the Human Genome Project to close to $5,000 in 2013 (Hayden 2014).
 From our perspective, the more extreme of modern anxieties about long-term, ineradicable technological unemployment, or a widespread lack of meaning because of changes in work patterns seem highly unlikely to come to pass. As has been true now for more than two centuries, technological advance will continue to improve the standard of living in many dramatic and unforeseeable ways. However, fundamental economic principles will continue to operate. Scarcities will still be with us, most notably of time itself. The law of comparative advantage strongly suggests that most workers will still have useful tasks to perform even in an economy where the capacities of robots and automation have increased considerably. The path of transition to this economy of the future may be disruptively painful for some workers and industries, as transitions tend to be.
 However, while the earliest transitions such as the Industrial Revolution were done with little governmental support for those displaced, this one will require public policy to ameliorate the harshest effects of dislocation. In particular, we believe that there is a distinct possibility that wages for some classes of workers may need to be supplemented through some income redistribution. In addition, it may be necessary to expand the set of publicly provided goods to include certain “primary goods” (Rawls 1971) such as food, housing, education, and health care that are necessary for a modern life to go well. For many others, cheaply produced goods and increasingly automated and freely available services should allow access to increasing levels of material well-being and health. We suspect that in this new world, as material goods like food, clothing, and housing become relatively less expensive, the connection between standard measurements of output and human well-being—a long-standing source of contention—will become even more tenuous. This world would truly be the fulfillment of Simon Kuznets’s (1934, p.
 7) dictum that “the welfare of a country can scarcely be inferred from a measure of national income.” In a world of cheap goods, while 48 Journal of Economic Perspectives inequality in terms of wealth or income may rise, inequality in the form of access to “primary” resources (in the Rawlsian sense) would be greatly diminished. The long-term trend toward greater leisure will continue, and one can even imagine an economy that reaches the stage in which only those who want to work actually will do so. The story of work in a world of continuing innovation is a good illustration of what is known as Amara’s Law, named after systems engineer Roy Amara, long-time president of the for-profit think-tank the Institute for the Future: “We tend to overestimate the effect of a technology in the short run and underestimate the effect in the long run.” As we reflect on the economics of this new economy, we let Keynes (1930) offer a word of advice: “Meanwhile there will be no harm in making mild preparations for our destiny, in encouraging, and experimenting in, the arts of life as well as the activities of purpose.
” 